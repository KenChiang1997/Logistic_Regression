{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import torch\n",
    "from   torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Proxy Data and train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        n = 5\n",
    "        m = 100\n",
    "\n",
    "        def sigmoid(z):\n",
    "            return 1/(1 + np.exp(-z))\n",
    "\n",
    "        beta_true = np.array([1, 0.5, -0.5] + [0]*(n - 3)) # True Beta \n",
    "        X      = (np.random.random((m, n)) - 0.5)*10\n",
    "        Y      = np.round(sigmoid(X @ beta_true + np.random.randn(m)*0.5))\n",
    "\n",
    "        print(beta_true)\n",
    "        # ---------- Generate Proxy Dataset , Convert ot Pytorch ---------- \n",
    "        self.data   =  torch.tensor(X)\n",
    "        self.label  =  torch.tensor(Y)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.data[index].float(),self.label[index].float().reshape(-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def get_input_dimmension(self):\n",
    "        return self.data.size()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.   0.5 -0.5  0.   0. ]\n",
      "[ 1.   0.5 -0.5  0.   0. ]\n"
     ]
    }
   ],
   "source": [
    "batch_size      = 10\n",
    "train_dataset   = Dataset()\n",
    "test_dataset    = Dataset()\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset , batch_size=batch_size)\n",
    "test_dataloader  = DataLoader(dataset=test_dataset  , batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration (1), X_train Size : torch.Size([10, 5]) , Y_train Size : torch.Size([10, 1])\n",
      "iteration (2), X_train Size : torch.Size([10, 5]) , Y_train Size : torch.Size([10, 1])\n",
      "iteration (3), X_train Size : torch.Size([10, 5]) , Y_train Size : torch.Size([10, 1])\n",
      "iteration (4), X_train Size : torch.Size([10, 5]) , Y_train Size : torch.Size([10, 1])\n",
      "iteration (5), X_train Size : torch.Size([10, 5]) , Y_train Size : torch.Size([10, 1])\n",
      "iteration (6), X_train Size : torch.Size([10, 5]) , Y_train Size : torch.Size([10, 1])\n",
      "iteration (7), X_train Size : torch.Size([10, 5]) , Y_train Size : torch.Size([10, 1])\n",
      "iteration (8), X_train Size : torch.Size([10, 5]) , Y_train Size : torch.Size([10, 1])\n",
      "iteration (9), X_train Size : torch.Size([10, 5]) , Y_train Size : torch.Size([10, 1])\n",
      "iteration (10), X_train Size : torch.Size([10, 5]) , Y_train Size : torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "for i,(data,label) in enumerate(train_dataloader):\n",
    "    print(f\"iteration ({i+1})\" + \", X_train Size :\",data.size() , \", Y_train Size :\",label.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    input_dim --> regression features\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,input_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "\n",
    "        self.linear  = nn.Linear(input_dim,1)  \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x_1    = self.linear(x)\n",
    "        y_pred = torch.sigmoid(x_1) \n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class parameters():\n",
    "\n",
    "    def __init__(self) :\n",
    "\n",
    "        self.learning_rate = 0.001 \n",
    "        self.epochs        = 1000\n",
    "        self.lambd         = 0.1\n",
    "        self.criterion     = nn.BCELoss()\n",
    "\n",
    "parameter = parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model     = LogisticRegression(input_dim=train_dataset.get_input_dimmension())\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=parameter.learning_rate,weight_decay=parameter.lambd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, loss 0.5810773372650146\n",
      "epoch 110, loss 0.29088208079338074\n",
      "epoch 210, loss 0.22094163298606873\n",
      "epoch 310, loss 0.19021907448768616\n",
      "epoch 410, loss 0.17336265742778778\n",
      "epoch 510, loss 0.16301816701889038\n",
      "epoch 610, loss 0.15624071657657623\n",
      "epoch 710, loss 0.15161103010177612\n",
      "epoch 810, loss 0.14835767447948456\n",
      "epoch 910, loss 0.14602549374103546\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(parameter.epochs):\n",
    "\n",
    "    for i,(data,label) in enumerate(train_dataloader):\n",
    "      \n",
    "        y_pred = model(data)\n",
    "        loss   = parameter.criterion(y_pred,label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print('epoch {}, loss {}'.format(epoch+batch_size, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.0440,  0.3621, -0.3835, -0.0032,  0.0376]], requires_grad=True)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Testing Result ---------\n",
      "-----------------------------------\n",
      "Iteration (1)  Accuracy =  1.0000\n",
      "Iteration (2)  Accuracy =  1.0000\n",
      "Iteration (3)  Accuracy =  1.0000\n",
      "Iteration (4)  Accuracy =  0.9000\n",
      "Iteration (5)  Accuracy =  1.0000\n",
      "Iteration (6)  Accuracy =  1.0000\n",
      "Iteration (7)  Accuracy =  0.9000\n",
      "Iteration (8)  Accuracy =  1.0000\n",
      "Iteration (9)  Accuracy =  1.0000\n",
      "Iteration (10)  Accuracy =  1.0000\n",
      "-----------------------------------\n",
      "Mean Accuracy =  0.98\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    list_accuracy = []\n",
    "    print(\"-\"*9 ,\"Testing Result\",\"-\"*9)\n",
    "    print(\"-\"*35)\n",
    "    for i,(data,label) in enumerate(test_dataloader):\n",
    "\n",
    "        y_predicted = model(data)\n",
    "        y_predicted_cls = y_predicted.round()\n",
    "        acc = y_predicted_cls.eq(label).sum() / float(label.shape[0])\n",
    "        list_accuracy.append(acc)\n",
    "        print(f\"Iteration ({i+1})  Accuracy = {acc: .4f}\")\n",
    "    \n",
    "    print(\"-\"*35)\n",
    "    print(\"Mean Accuracy = \",np.mean(list_accuracy))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0cf3df4d71a28079a44c5da4fc89abaccf068750c614e1d3e46e1e6a2e981cfe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
